{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "248ba93d",
   "metadata": {},
   "source": [
    "# AWS S3 Vectors Sematic Search \n",
    "\n",
    "This notebook demonstrates how to use Amazon S3 Vectors for semantic search by creating an index, uploading vectors, and querying them using a custom text model. It includes steps for data preparation, vector encoding, and querying the S3 Vectors service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8f1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------------------------\n",
    "# Setup Prerequisites for Semantic Search with AWS S3Vector\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "%pip install pandas numpy torch boto3 sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c58f971e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the file...\n",
      "File loaded and filtered.\n",
      "Vocabularies built:\n",
      "- States: 52\n",
      "- NDCs: 270\n",
      "- Drugs: 193\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# Load and preprocess the data\n",
    "# ------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import boto3 \n",
    "\n",
    "# Load the CSV file\n",
    "print('Loading the file...')\n",
    "df_raw = pd.read_csv(\"../data/medicaid-drugs.csv\")\n",
    "\n",
    "# Get first 100 records per state\n",
    "df = df_raw.groupby('State', group_keys=False).head(100).copy()\n",
    "\n",
    "print('File loaded and filtered.')\n",
    "\n",
    "# Fill missing values for key numeric fields\n",
    "df.fillna({\n",
    "    'Number of Prescriptions': 0,\n",
    "    'Total Amount Reimbursed': 0\n",
    "}, inplace=True)\n",
    "\n",
    "# Build vocabularies for categorical features\n",
    "state_vocab = {s: i for i, s in enumerate(df['State'].unique())}\n",
    "ndc_vocab = {s: i for i, s in enumerate(df['NDC'].unique())}\n",
    "drug_vocab = {s: i for i, s in enumerate(df['Product Name'].unique())}\n",
    "\n",
    "print('Vocabularies built:')\n",
    "print(f'- States: {len(state_vocab)}')\n",
    "print(f'- NDCs: {len(ndc_vocab)}')\n",
    "print(f'- Drugs: {len(drug_vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b643f941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode categorical data\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical data as integers\n",
    "df['state_id'] = df['State'].map(state_vocab)\n",
    "df['ndc_id'] = df['NDC'].map(ndc_vocab)\n",
    "df['drug_id'] = df['Product Name'].map(drug_vocab)\n",
    "\n",
    "print('Encode categorical data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02336ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert to tensors\n"
     ]
    }
   ],
   "source": [
    "# Normalize numeric features\n",
    "numeric_feats = df[['Number of Prescriptions', 'Total Amount Reimbursed']].astype(np.float32)\n",
    "numeric_feats = (numeric_feats - numeric_feats.mean()) / (numeric_feats.std() + 1e-6)\n",
    "\n",
    "# Convert to tensors\n",
    "state_ids = torch.tensor(df['state_id'].values, dtype=torch.long)\n",
    "ndc_ids = torch.tensor(df['ndc_id'].values, dtype=torch.long)\n",
    "drug_ids = torch.tensor(df['drug_id'].values, dtype=torch.long)\n",
    "numeric_tensor = torch.tensor(numeric_feats.values, dtype=torch.float32)\n",
    "\n",
    "print('Convert to tensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1211f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------\n",
    "# Define your encoder\n",
    "# ------------------------------------------\n",
    "class MedicaidDrugEncoder(nn.Module):\n",
    "    def __init__(self, state_vocab_size, ndc_vocab_size, drug_vocab_size, embed_dim, num_inputs):\n",
    "        super().__init__()\n",
    "        self.state_embed = nn.Embedding(state_vocab_size, embed_dim)\n",
    "        self.ndc_embed = nn.Embedding(ndc_vocab_size, embed_dim)\n",
    "        self.drug_embed = nn.Embedding(drug_vocab_size, embed_dim)\n",
    "        self.numeric_proj = nn.Linear(num_inputs, embed_dim)\n",
    "\n",
    "        self.combined_proj = nn.Sequential(\n",
    "            nn.Linear(embed_dim * 4, 128),   # Combine all input embeddings\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32)               # ðŸ”½ Final projection to 32-d\n",
    "        )\n",
    "\n",
    "    def forward(self, state_ids, ndc_ids, drug_ids, numeric_tensor):\n",
    "\n",
    "        state_vec = self.state_embed(state_ids)\n",
    "        ndc_vec = self.ndc_embed(ndc_ids)\n",
    "        drug_vec = self.drug_embed(drug_ids)\n",
    "        numeric_vec = self.numeric_proj(numeric_tensor)\n",
    "\n",
    "        # Concatenate all parts\n",
    "        combined = torch.cat([state_vec, ndc_vec, drug_vec, numeric_vec], dim=-1)\n",
    "\n",
    "        # Project to final 32-d vector\n",
    "        output = self.combined_proj(combined)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1a3fc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding completed : Embedding shape:  (5200, 32)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# Generate embeddings\n",
    "# ------------------------------------------\n",
    "embed_dim = 32\n",
    "encoder = MedicaidDrugEncoder(\n",
    "    len(state_vocab), len(ndc_vocab), len(drug_vocab),\n",
    "    embed_dim=embed_dim,\n",
    "    num_inputs=2\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    embeddings = encoder(state_ids, ndc_ids, drug_ids, numeric_tensor)\n",
    "\n",
    "embedding_matrix = embeddings.numpy().astype(np.float32)\n",
    "\n",
    "print('Embedding completed : Embedding shape: ', embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea67aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# AWS S3 Vectors Infrastructure\n",
    "# ------------------------------------------\n",
    "bucket_name = 'medicaid-drug-vectors'\n",
    "index_name = 'medicaid-2025-index' \n",
    "region = 'us-east-1'\n",
    "\n",
    "client = boto3.client('s3vectors', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4834c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index for 32-dimensional vectors\n",
    "\n",
    "client.create_index(\n",
    "    vectorBucketName=bucket_name,\n",
    "    indexName=index_name,\n",
    "    dataType='float32',\n",
    "    dimension=32,\n",
    "    distanceMetric='cosine'\n",
    ")\n",
    "\n",
    "print(f'Index {index_name} created in bucket {bucket_name}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148b5d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 5200 vectors for upload.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming embedding_matrix is shape (batch_size, 32)\n",
    "vectors_to_upload = []\n",
    "\n",
    "for i, row in enumerate(embedding_matrix):\n",
    "    metadata_row = df.iloc[i]\n",
    "    vectors_to_upload.append({\n",
    "        \"key\": f\"drug-vector-{i}\",\n",
    "        \"data\": {\n",
    "            \"float32\": row.tolist()  # Convert each vector to a list of floats\n",
    "        },\n",
    "        \"metadata\": {\n",
    "            \"state\": metadata_row.get(\"State\", \"UNK\"),\n",
    "            \"year\": int(metadata_row.get(\"Year\", 0)),\n",
    "            \"drugname\": metadata_row.get(\"Product Name\", \"unknown\")\n",
    "        }\n",
    "    })\n",
    "\n",
    "print(f\"Prepared {len(vectors_to_upload)} vectors for upload.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788eb320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload in batches\n",
    "\n",
    "batch_size = 500\n",
    "for i in range(0, len(vectors_to_upload), batch_size):\n",
    "    batch = vectors_to_upload[i:i+batch_size]\n",
    "    response = client.put_vectors(\n",
    "        vectorBucketName=bucket_name,\n",
    "        indexName=index_name,\n",
    "        vectors=batch\n",
    "    )\n",
    "    print(f\"Uploaded batch {i // batch_size + 1}: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77b58f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Perform a semantic search\n",
    "# -------------------------\n",
    "\n",
    "# âœ… Step 1: Define a text encoder\n",
    "\n",
    "# Custom filter query\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a transformer and reduce to 32-dim\n",
    "text_model = SentenceTransformer(\"all-MiniLM-L6-v2\") \n",
    "\n",
    "# Reduce to 32-dim with a linear projection\n",
    "reducer = nn.Linear(384, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "27522d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#âœ… Step 2: Encode the user query \n",
    "\n",
    "input_text = \"diabetes treatment\"\n",
    "embedding_custom = text_model.encode(input_text, convert_to_numpy=True)  # shape: (384,)\n",
    "\n",
    "# Reduce to 32-dim\n",
    "embedding_32 = reducer(torch.tensor(embedding_custom)).detach().numpy().astype(np.float32)\n",
    "query_vector_custom = embedding_32.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3c1d1e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#âœ… Step 3: Query the S3 Vector index\n",
    "\n",
    "response_custom = client.query_vectors(\n",
    "    vectorBucketName=bucket_name,\n",
    "    indexName=index_name,\n",
    "    queryVector={\n",
    "        \"float32\": query_vector_custom\n",
    "    },\n",
    "    filter={\"state\": \"SC\"},\n",
    "    topK=3,\n",
    "    returnMetadata=True,\n",
    "    returnDistance=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9ce5be87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match key: drug-vector-4199\n",
      "Distance: 0.7495\n",
      "Metadata: {'year': 2022, 'state': 'SC', 'drugname': 'HUMULIN N '}\n",
      "Match key: drug-vector-4181\n",
      "Distance: 0.7550\n",
      "Metadata: {'state': 'SC', 'year': 2022, 'drugname': 'INSULIN LI'}\n",
      "Match key: drug-vector-4182\n",
      "Distance: 0.7551\n",
      "Metadata: {'year': 2022, 'drugname': 'INSULIN LI', 'state': 'SC'}\n"
     ]
    }
   ],
   "source": [
    "# Results for semantic search\n",
    "for match in response_custom.get(\"vectors\", []):\n",
    "    print(f\"Match key: {match['key']}\")\n",
    "    print(f\"Distance: {match['distance']:.4f}\")\n",
    "    print(f\"Metadata: {match.get('metadata', {})}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
